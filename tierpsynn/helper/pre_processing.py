# %%

import os
import pickle
from contextlib import contextmanager
from pathlib import Path
from typing import Union

import cv2
import h5py
import jax
import jax.numpy as jnp
import numpy as np

import tierpsynn as tnn
from deeptangle import build_model, utils
from tierpsy.analysis.split_fov.FOVMultiWellsSplitter import FOVMultiWellsSplitter
from tierpsy.helper.params.tracker_param import SplitFOVParams
from tierpsynn.extras.Para_config import Config
from tierpsynn.helper.Readers.readLoopBio import readLoopBio
from tierpsynn.helper.Readers.readVideoHDF5 import readVideoHDF5
from tierpsynn.helper.Readers.readVideomp4 import readVideomp4

# %%


def _return_masked_image(params_input):
    # Path("inference/configs")
    json_fname = Path(tnn.MWP_PATH).joinpath(params_input.MW_mapping)

    splitfov_params = SplitFOVParams(json_file=json_fname)
    shape, edge_frac, sz_mm = splitfov_params.get_common_params()
    uid, rig, ch, mwp_map = splitfov_params.get_params_from_filename(
        params_input.raw_fname
    )
    px2um = params_input.microns_per_pixel

    # read image
    vid = selectVideoReader(params_input.raw_fname)
    _, img = vid.read_frame(100)

    fovsplitter = FOVMultiWellsSplitter(
        img,
        microns_per_pixel=px2um,
        well_shape=shape,
        well_size_mm=sz_mm,
        well_masked_edge=edge_frac,
        camera_serial=uid,
        rig=rig,
        channel=ch,
        wells_map=mwp_map,
    )
    # fig = fovsplitter.plot_wells()
    return fovsplitter


@contextmanager
def selectVideoReader(video_file: os.PathLike):
    # open video to read
    isHDF5video = video_file.endswith(".hdf5")

    isLoopBio = video_file.endswith(".yaml")

    isMP4video = video_file.endswith(".mp4")

    if isHDF5video:
        # use tables to read hdf5 with lz4 compression generated by the Gecko
        # plugin
        vid = readVideoHDF5(video_file)
    elif isLoopBio:
        # use opencv VideoCapture
        vid = readLoopBio(video_file)
    elif isMP4video:
        # use opencv VideoCapture
        vid = readVideomp4(video_file)
    else:
        raise Exception("Only HDF5, mp4 and loopbio videos are supported so far")

    if vid.width == 0 or vid.height == 0:
        raise RuntimeError
    try:
        return vid
    finally:
        vid.release()


def _return_masked_image(params_input):
    json_fname = Path(tnn.MWP_PATH).joinpath(params_input.MW_mapping)

    splitfov_params = SplitFOVParams(json_file=json_fname)
    shape, edge_frac, sz_mm = splitfov_params.get_common_params()
    uid, rig, ch, mwp_map = splitfov_params.get_params_from_filename(
        params_input.raw_fname
    )
    px2um = params_input.microns_per_pixel

    # read image
    vid = selectVideoReader(str(params_input.raw_fname))
    _, img = vid.read_frame(100)

    fovsplitter = FOVMultiWellsSplitter(
        img,
        microns_per_pixel=px2um,
        well_shape=shape,
        well_size_mm=sz_mm,
        well_masked_edge=edge_frac,
        camera_serial=uid,
        rig=rig,
        channel=ch,
        wells_map=mwp_map,
    )
    # fig = fovsplitter.plot_wells()
    return fovsplitter


def restore(experiment_dir: str, broadcast: bool = False):
    path = Path(experiment_dir)

    if not path.exists():
        raise FileNotFoundError(f"{experiment_dir} does not exist.")

    with path.joinpath("tree.pkl").open("rb") as f:
        tree_struct = pickle.load(f)

    leaves, treedef = jax.tree_util.tree_flatten(tree_struct)
    with path.joinpath("arrays.npy").open("rb") as f:
        flat_state = [jnp.load(f) for _ in leaves]

    state = jax.tree_util.tree_unflatten(treedef, flat_state)

    if broadcast:
        num_devices = jax.local_device_count()
        state = utils.broadcast_sharded(state, num_devices)

    return state


def load_real_model(params_input, broadcast: bool = False):
    """
    Builds a model using the weights and the transformation matrix found at the directory.

    Parameters:
        origin_dir: Path to the folder where the weights are.
        broadcast: Whether to broadcast the weights to the number of devices.

    Returns:
        The forward function and the state of the model.
    """
    path = Path(params_input.model)
    with path.joinpath("eigenworms_transform.npy").open("rb") as f:
        A = jnp.load(f)

    forward_fn = build_model(
        A, params_input.n_suggestions, params_input.latent_dim, params_input.nframes
    )

    state = restore(params_input.model, broadcast=broadcast)
    return forward_fn, state


def is_hdf5_empty(file_path):
    try:
        with h5py.File(file_path, "r") as hdf_file:
            # Check if the root group is empty
            if len(hdf_file) == 0:
                return True
            else:
                return False
    except Exception as e:
        print(f"Error reading HDF5 file: {e}")
        return False


def _adaptive_thresholding(img: np.uint8, params_input):
    # if params_input.is_light:
    img = 255 - img
    th = np.array(
        [
            cv2.adaptiveThreshold(
                img[j, :],
                255,
                cv2.ADAPTIVE_THRESH_MEAN_C,
                cv2.THRESH_BINARY,
                params_input.block_size,
                params_input.Constant,
            )
            == 0
            for j in (range(img.shape[0]))
        ]
    )
    return th


def _mean_bgd(clip):
    mean_image = np.mean(clip, axis=0)
    # if scale_factor:
    # mean_image = rescale(
    #   mean_image, scale=(1, scale_factor, scale_factor), anti_aliasing=True
    # )

    return mean_image


def _padding_side(image, scale_factor=None, n_pads=16):
    if scale_factor:
        # image = rescale(image, scale=(scale_factor, scale_factor), anti_aliasing=True)
        image = jax.image.resize(
            image,
            [int(image.shape[0] * scale_factor), int(image.shape[1] * scale_factor)],
            method="cubic",
        )

    pad_bottom, pad_right = (
        n_pads - image.shape[0] % n_pads,
        n_pads - image.shape[1] % n_pads,
    )
    return pad_bottom, pad_right


def _initialise_parameters(input_vid: str, params_well: Union[int, str]):
    """ "
    Initialise the paramaters
    """
    params_input = Config(params_well, input_vid)

    # Prepare save directory
    save_name = Path(
        str(Path(params_input.raw_fname).parent).replace("RawVideos", "Results_NN")
    )
    save_name.mkdir(exist_ok=True, parents=True)

    # Load model and state
    forward_fn, state = load_real_model(params_input, broadcast=False)
    state_single = utils.single_from_sharded(state)

    # Determine frame range
    min_frame = params_input.min_frame if params_input.min_frame else 0
    max_frame = (
        params_input.max_frame
        if params_input.max_frame
        else int(params_input.input_video.tot_frames)
    )
    max_frame_init = params_input.max_frame_init + min_frame

    scale_factor = params_input.scale_factor

    # Load and preprocess video
    store = selectVideoReader(params_input.raw_fname)
    pre_procesing_clip = np.array(
        [
            frame_data[1]
            for frame in range(min_frame, max_frame, int(max_frame / 10))
            if (frame_data := store.read_frame(frame))[1] is not None
        ]
    )

    store.release()
    if params_input.is_light:
        pre_procesing_clip = 255 - pre_procesing_clip
    bgd = _mean_bgd(pre_procesing_clip)
    pad_bottom, pad_right = _padding_side(bgd, scale_factor)

    # Turn off the background removal
    if not params_input.bgd_removal:
        bgd = 0

    return params_input, {
        "save_name": save_name,
        "forward_fn": forward_fn,
        "state_single": state_single,
        "min_frame": min_frame,
        "max_frame": max_frame,
        "max_frame_init": max_frame_init,
        "bgd": bgd,
        "pad_bottom": pad_bottom,
        "pad_right": pad_right,
        "scale_factor": scale_factor,
    }


def _initialise_parameters_features(input_vid: str, params_well: Union[int, str]):
    """ "
    Initialise the paramaters
    """
    params_input = Config(params_well, input_vid)

    # Prepare save directory
    save_name = Path(
        str(Path(params_input.raw_fname).parent).replace("RawVideos", "Results_NN")
    )
    save_name.mkdir(exist_ok=True, parents=True)

    # Load model and state

    return params_input, save_name


# %%
if __name__ == "__main__":
    # RawVideos = "/home/weheliye@cscdom.csc.mrc.ac.uk/behavgenom_mnt/Weheliye/Paper_4_Andre/Data/SyngentaScreen/RawVideos/20191212/syngenta_screen_run1_prestim_20191212_144914.22956829/metadata.yaml"
    RawVideos = "/home/weheliye@cscdom.csc.mrc.ac.uk/behavgenom_mnt/Weheliye/Paper_4_Andre/Data/transfer_2833382_files_c35b8490/RawVideos/MultiwormTest.mp4"
    params_well = "/home/weheliye@cscdom.csc.mrc.ac.uk/behavgenom_mnt/Weheliye/Paper_4_Andre/Data/transfer_2833382_files_c35b8490/loopbio_rig_6WP_splitFOV_NN_20220202.json"
    params_input, params_results = _initialise_parameters(RawVideos, params_well)


# %%
